{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2S8I2ny-ovS"
   },
   "source": [
    "# ANLP: Sentiment Classification\n",
    "\n",
    "In this assignment, you will be investigating NLP methods for distinguishing positive and negative reviews written about movies.\n",
    "\n",
    "For assessment, you are expected to complete and submit this notebook file.  When answers require code, you may import and use library functions (unless explicitly told otherwise).  All of your own code should be included in the notebook rather than imported from elsewhere.  Written answers should also be included in the notebook.  You should insert as many extra cells as you want and change the type between code and markdown as appropriate.\n",
    "\n",
    "In order to avoid misconduct, you should not talk about the assignment questions with your peers.  If you are not sure what a question is asking you to do or have any other questions, please ask me or one of the Teaching Assistants.\n",
    "\n",
    "Marking guidelines are provided as a separate document.\n",
    "\n",
    "The first few cells contain code to set-up the assignment and bring in some data.   In order to provide unique datasets for analysis by different students, you must enter your candidate number in the following cell.  Otherwise do not change the code in these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "1gXQAZas-l9c"
   },
   "outputs": [],
   "source": [
    "candidateno=277180 #this MUST be updated to your candidate number so that you get a unique data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nk8JTP88A8vs",
    "outputId": "4cce3b1a-6f62-492b-a814-ac96f60be492"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#do not change the code in this cell\n",
    "#preliminary imports\n",
    "\n",
    "#set up nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('movie_reviews')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "#for setting up training and testing data\n",
    "import random\n",
    "\n",
    "#useful other tools\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from itertools import zip_longest\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.classify.api import ClassifierI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "BHBkzAccCVaZ"
   },
   "outputs": [],
   "source": [
    "#do not change the code in this cell\n",
    "def split_data(data, ratio=0.7): # when the second argument is not given, it defaults to 0.7\n",
    "    \"\"\"\n",
    "    Given corpus generator and ratio:\n",
    "     - partitions the corpus into training data and test data, where the proportion in train is ratio,\n",
    "\n",
    "    :param data: A corpus generator.\n",
    "    :param ratio: The proportion of training documents (default 0.7)\n",
    "    :return: a pair (tuple) of lists where the first element of the\n",
    "            pair is a list of the training data and the second is a list of the test data.\n",
    "    \"\"\"\n",
    "\n",
    "    data = list(data)\n",
    "    n = len(data)\n",
    "    train_indices = random.sample(range(n), int(n * ratio))\n",
    "    test_indices = list(set(range(n)) - set(train_indices))\n",
    "    train = [data[i] for i in train_indices]\n",
    "    test = [data[i] for i in test_indices]\n",
    "    return (train, test)\n",
    "\n",
    "\n",
    "def get_train_test_data():\n",
    "\n",
    "    #get ids of positive and negative movie reviews\n",
    "    pos_review_ids=movie_reviews.fileids('pos')\n",
    "    neg_review_ids=movie_reviews.fileids('neg')\n",
    "\n",
    "    #split positive and negative data into training and testing sets\n",
    "    pos_train_ids, pos_test_ids = split_data(pos_review_ids)\n",
    "    neg_train_ids, neg_test_ids = split_data(neg_review_ids)\n",
    "    #add labels to the data and concatenate\n",
    "    training = [(movie_reviews.words(f),'pos') for f in pos_train_ids]+[(movie_reviews.words(f),'neg') for f in neg_train_ids]\n",
    "    testing = [(movie_reviews.words(f),'pos') for f in pos_test_ids]+[(movie_reviews.words(f),'neg') for f in neg_test_ids]\n",
    "\n",
    "    return training, testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1N3LWwBYICPP"
   },
   "source": [
    "When you have run the cell below, your unique training and testing samples will be stored in `training_data` and `testing_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HJLegkdPFUJA",
    "outputId": "8603fa4b-1983-477b-90c3-bde41379c136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of training data is 1400\n",
      "The amount of testing data is 600\n",
      "The representation of a single data item is below\n",
      "(['david', 'mamet', 'has', 'long', 'been', 'my', ...], 'pos')\n"
     ]
    }
   ],
   "source": [
    "#do not change the code in this cell\n",
    "random.seed(candidateno)\n",
    "training_data,testing_data=get_train_test_data()\n",
    "print(\"The amount of training data is {}\".format(len(training_data)))\n",
    "print(\"The amount of testing data is {}\".format(len(testing_data)))\n",
    "print(\"The representation of a single data item is below\")\n",
    "print(training_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbTq6eGv2XT2"
   },
   "source": [
    "1)  \n",
    "a) **Generate** a list of 10 content words which are representative of the positive reviews in your training data.\n",
    "\n",
    "b) **Generate** a list of 10 content words which are representative of the negative reviews in your training data.\n",
    "\n",
    "c) **Explain** what you have done and why\n",
    "\n",
    "[20\\%]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXHrtNCg2XT4"
   },
   "source": [
    "In regards to my **Sentiment Classification** assignment, I've been told to work on the **movie_reviews corpus**. The corpus I've been given has already been split into training and testing sets in a **70:30 ratio** using the split_data function. Our aim is to find content words that respresent positive and negative words in our training dataset.\n",
    "\n",
    "Currently, each review / document in my training set is represented as a list of tokens.  In most basic applications, the sequence of words in a text is considered unimportant, and we use a bag-of-words representation of the document. In the cell below, I have used a function **FreqDist** from **nltk.Probability** to construct the bag-of-words in the training set while keeping the labels pos and neg intact (***FreqDist*** *is useful in text pre-processing, additionally it helps to understand how frequently the words has appeared which is further used to find most common words*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvFu36xZ2XT5",
    "outputId": "11e1149c-5b8d-49e3-e45f-b7e5d04d2790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency Distribution before pre-processing steps for Training Data: (FreqDist({',': 33, '.': 28, 'the': 28, 'a': 21, 'to': 20, 'is': 20, 'his': 16, 'of': 15, \"'\": 14, 'and': 13, ...}), 'pos')\n",
      "Frequency Distribution before pre-processing steps for Testing Data: (FreqDist({'the': 46, ',': 43, \"'\": 25, '.': 23, 'and': 21, '(': 18, ')': 18, 'in': 18, 'a': 15, 'to': 15, ...}), 'pos')\n"
     ]
    }
   ],
   "source": [
    "#Document Representation\n",
    "training_basic=[(FreqDist(wordlist),label) for (wordlist,label) in training_data]\n",
    "testing_basic=[(FreqDist(wordlist),label) for (wordlist,label) in testing_data]\n",
    "\n",
    "print(f\"Frequency Distribution before pre-processing steps for Training Data: {training_basic[0]}\")\n",
    "print(f\"Frequency Distribution before pre-processing steps for Testing Data: {testing_basic[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgePc9hV2XT_"
   },
   "source": [
    "Many of the words in the document representation output are punctuations and stopwords. To remove stopwords and punctuations i.e. to apply the preprocessing steps, I ran my **normalise function** on my **training_data**, the output printed is excluding the punctuations and stopwords which is stored in **filtered_words** variable. As the pre-processing steps are done, I have again used the FreqDist library and saved the output in the **training_norm** along with their frequency, this provides a cleaner representation of word frequencies in the preprocessed training data. The training_norm is then utilized in the next stages involved in generating the content words representing the positive and negative reviews.\n",
    "\n",
    "Here, the normalise function is performing two key preprocessing steps:\n",
    "1.   It converts all words to lowercase to ensure case insensitivity. This is acheived by using predefined python function **.lower()**.\n",
    "2.   It then removes stopwords and non-alphabetic words from the lowered list to clean and prepare the text data for further analysis. This is done using **.isalpha()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JauTzY5N2XUB",
    "outputId": "f6386a41-f0be-4fa8-8547-05f2a1c718ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data after pre-processing steps: ['david', 'mamet', 'long', 'favorite', 'screenwriter', 'director', 'distinctive', 'often', 'ingenious', 'dialogue', 'laid', 'back', 'style', 'direction', 'nearly', 'movies', 'absolutely', 'irresistible', 'tend', 'thickly', 'layered', 'deceptive', 'productions', 'require', 'audience', 'look', 'film', 'less', 'superficial', 'manner', 'plot', 'seems', 'require', 'order', 'discern', 'concealed', 'message', 'sometimes', 'even', 'concealed', 'storyline', 'although', 'real', 'plot', 'new', 'project', 'winslow', 'boy', 'slightly', 'conspicuous', 'endeavors', 'still', 'brilliantly', 'complex', 'consistently', 'riveting', 'motion', 'picture', 'honor', 'sacrifice', 'difference', 'commonly', 'known', 'justice', 'right', 'oh', 'rated', 'g', 'incidentally', 'first', 'time', 'mamet', 'decided', 'adapt', 'someone', 'else', 'work', 'namely', 'play', 'terrence', 'rattigan', 'set', 'century', 'casts', 'nigel', 'hawthorne', 'lead', 'role', 'arthur', 'winslow', 'rich', 'aging', 'man', 'finds', 'year', 'old', 'son', 'ronnie', 'kicked', 'naval', 'academy', 'allegedly', 'stealing', 'shilling', 'postal', 'note', 'asks', 'boy', 'father', 'ronnie', 'answers', 'enough', 'arthur', 'oldest', 'daughter', 'rebecca', 'pidgeon', 'immediately', 'starts', 'crusade', 'bring', 'son', 'case', 'court', 'enlist', 'help', 'sir', 'robert', 'morton', 'notorious', 'attorney', 'help', 'achieve', 'formidably', 'daunting', 'task', 'seems', 'fairly', 'frivolous', 'matter', 'look', 'winslow', 'case', 'trial', 'century', 'arthur', 'determined', 'keep', 'family', 'word', 'clean', 'willing', 'go', 'quite', 'far', 'make', 'sure', 'soon', 'enough', 'sir', 'robert', 'morton', 'along', 'rest', 'country', 'becomes', 'equally', 'wrapped', 'proceedings', 'david', 'mamet', 'script', 'tighten', 'hone', 'dialogue', 'style', 'still', 'fairly', 'apparent', 'characters', 'still', 'talk', 'trademark', 'staccatto', 'lines', 'still', 'tension', 'present', 'conversations', 'ordinary', 'writer', 'would', 'able', 'make', 'tense', 'mamet', 'norm', 'refreshing', 'see', 'mamet', 'deviate', 'world', 'crooks', 'gangsters', 'con', 'men', 'wonderful', 'films', 'nigel', 'hawthorne', 'performance', 'nearly', 'flawless', 'delivery', 'dignified', 'yet', 'pompous', 'man', 'seems', 'getting', 'beaten', 'game', 'pity', 'man', 'also', 'like', 'rebecca', 'pidgeon', 'david', 'mamet', 'wife', 'gave', 'fairly', 'awful', 'performance', 'spanish', 'prisoner', 'top', 'game', 'arthur', 'oldest', 'daughter', 'flailing', 'feminist', 'gives', 'winslow', 'case', 'way', 'making', 'lack', 'success', 'women', 'suffrage', 'movement', 'winslow', 'boy', 'wonderful', 'movie', 'avoids', 'cliches', 'seemingly', 'inevitable', 'courtroom', 'scene', 'shoots', 'higher', 'wants', 'make', 'real', 'impact', 'rather', 'phony', 'one', 'honest', 'feel', 'anything', 'profound', 'courtroom', 'scenes', 'films', 'like', 'time', 'kill', 'wanted', 'movie', 'epitome', 'subtlety', 'powerful', 'without', 'emotional', 'sad', 'without', 'even', 'trying', 'depressing', 'david', 'mamet', 'churn', 'great', 'scripts', 'movie', 'proves', 'ever', 'doubted', 'hell', 'director', 'almost', 'national', 'treasure', 'films', 'deserve', 'genre', 'eugene', 'novikov']\n",
      "Testing Data after pre-processing steps: ['films', 'adapted', 'comic', 'books', 'plenty', 'success', 'whether', 'superheroes', 'batman', 'superman', 'spawn', 'geared', 'toward', 'kids', 'casper', 'arthouse', 'crowd', 'ghost', 'world', 'never', 'really', 'comic', 'book', 'like', 'hell', 'starters', 'created', 'alan', 'moore', 'eddie', 'campbell', 'brought', 'medium', 'whole', 'new', 'level', 'mid', 'part', 'series', 'called', 'watchmen', 'say', 'moore', 'campbell', 'thoroughly', 'researched', 'subject', 'jack', 'ripper', 'would', 'like', 'saying', 'michael', 'jackson', 'starting', 'look', 'little', 'odd', 'book', 'graphic', 'novel', 'pages', 'long', 'includes', 'nearly', 'consist', 'nothing', 'footnotes', 'words', 'dismiss', 'film', 'source', 'get', 'past', 'whole', 'comic', 'book', 'thing', 'might', 'find', 'another', 'stumbling', 'block', 'hell', 'directors', 'albert', 'allen', 'hughes', 'getting', 'hughes', 'brothers', 'direct', 'seems', 'almost', 'ludicrous', 'casting', 'carrot', 'top', 'well', 'anything', 'riddle', 'better', 'direct', 'film', 'set', 'ghetto', 'features', 'really', 'violent', 'street', 'crime', 'mad', 'geniuses', 'behind', 'menace', 'ii', 'society', 'ghetto', 'question', 'course', 'whitechapel', 'london', 'east', 'end', 'filthy', 'sooty', 'place', 'whores', 'called', 'unfortunates', 'starting', 'get', 'little', 'nervous', 'mysterious', 'psychopath', 'carving', 'profession', 'surgical', 'precision', 'first', 'stiff', 'turns', 'copper', 'peter', 'godley', 'robbie', 'coltrane', 'world', 'enough', 'calls', 'inspector', 'frederick', 'abberline', 'johnny', 'depp', 'blow', 'crack', 'case', 'abberline', 'widower', 'prophetic', 'dreams', 'unsuccessfully', 'tries', 'quell', 'copious', 'amounts', 'absinthe', 'opium', 'upon', 'arriving', 'whitechapel', 'befriends', 'unfortunate', 'named', 'mary', 'kelly', 'heather', 'graham', 'say', 'proceeds', 'investigate', 'horribly', 'gruesome', 'crimes', 'even', 'police', 'surgeon', 'stomach', 'think', 'anyone', 'needs', 'briefed', 'jack', 'ripper', 'go', 'particulars', 'say', 'moore', 'campbell', 'unique', 'interesting', 'theory', 'identity', 'killer', 'reasons', 'chooses', 'slay', 'comic', 'bother', 'cloaking', 'identity', 'ripper', 'screenwriters', 'terry', 'hayes', 'vertical', 'limit', 'rafael', 'yglesias', 'les', 'mis', 'rables', 'good', 'job', 'keeping', 'hidden', 'viewers', 'end', 'funny', 'watch', 'locals', 'blindly', 'point', 'finger', 'blame', 'jews', 'indians', 'englishman', 'could', 'never', 'capable', 'committing', 'ghastly', 'acts', 'hell', 'ending', 'whistling', 'stonecutters', 'song', 'simpsons', 'days', 'holds', 'back', 'electric', 'car', 'made', 'steve', 'guttenberg', 'star', 'worry', 'make', 'sense', 'see', 'onto', 'hell', 'appearance', 'certainly', 'dark', 'bleak', 'enough', 'surprising', 'see', 'much', 'looks', 'like', 'tim', 'burton', 'film', 'planet', 'apes', 'times', 'seems', 'like', 'sleepy', 'hollow', 'print', 'saw', 'completely', 'finished', 'color', 'music', 'finalized', 'comments', 'marilyn', 'manson', 'cinematographer', 'peter', 'deming', 'say', 'word', 'ably', 'captures', 'dreariness', 'victorian', 'era', 'london', 'helped', 'make', 'flashy', 'killing', 'scenes', 'remind', 'crazy', 'flashbacks', 'twin', 'peaks', 'even', 'though', 'violence', 'film', 'pales', 'comparison', 'black', 'white', 'comic', 'oscar', 'winner', 'martin', 'childs', 'shakespeare', 'love', 'production', 'design', 'turns', 'original', 'prague', 'surroundings', 'one', 'creepy', 'place', 'even', 'acting', 'hell', 'solid', 'dreamy', 'depp', 'turning', 'typically', 'strong', 'performance', 'deftly', 'handling', 'british', 'accent', 'ians', 'holm', 'joe', 'gould', 'secret', 'richardson', 'dalmatians', 'log', 'great', 'supporting', 'roles', 'big', 'surprise', 'graham', 'cringed', 'first', 'time', 'opened', 'mouth', 'imagining', 'attempt', 'irish', 'accent', 'actually', 'half', 'bad', 'film', 'however', 'good', 'r', 'strong', 'violence', 'gore', 'sexuality', 'language', 'drug', 'content']\n",
      "\n",
      "Frequency Distribution after pre-processing steps for Training Data: (FreqDist({'mamet': 7, 'winslow': 5, 'david': 4, 'still': 4, 'arthur': 4, 'seems': 3, 'boy': 3, 'man': 3, 'case': 3, 'fairly': 3, ...}), 'pos')\n",
      "Frequency Distribution after pre-processing steps for Testing Data: (FreqDist({'comic': 5, 'hell': 5, 'film': 5, 'like': 4, 'say': 4, 'book': 3, 'moore': 3, 'campbell': 3, 'ripper': 3, 'even': 3, ...}), 'pos')\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "#Document Pre-processing Techniques\n",
    "def normalise(word_list):\n",
    "  #making the word_list in lowercase (not needed but for proper analysis included this step)\n",
    "  lower_case = [words.lower() for words in word_list]\n",
    "  #removing stopwords\n",
    "  filtered_words = [words for words in lower_case if words.isalpha() and words not in stop]\n",
    "  return filtered_words\n",
    "\n",
    "#printing the data after removing of punctuations and stopwords\n",
    "print(f\"Training Data after pre-processing steps: {normalise(training_data[0][0])}\")\n",
    "print(f\"Testing Data after pre-processing steps: {normalise(testing_data[0][0])}\")\n",
    "print()\n",
    "\n",
    "training_norm = [(FreqDist(normalise(word_list)),label) for (word_list,label) in training_data]\n",
    "testing_norm = [(FreqDist(normalise(word_list)),label) for (word_list,label) in testing_data]\n",
    "\n",
    "print(f\"Frequency Distribution after pre-processing steps for Training Data: {training_norm[0]}\")\n",
    "print(f\"Frequency Distribution after pre-processing steps for Testing Data: {testing_norm[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjkUsI6Pd-7y"
   },
   "source": [
    "There are multiple ways to generate/identify content word list out which are using most frequent words logic and another using a threshold logic. Out of these two I have found the most frequent words logic more suitable as it concentrates on words that are more exclusive between the 2 classes.\n",
    "\n",
    "To identify words that are more suggestive of one sentiment category than the other, I built a function called **most_freq_words**. This procedure comprised:\n",
    "\n",
    "1.   Calculating the difference between the frequency distributions of positive and negative reviews in my training data.\n",
    "2.   Sorting this difference and selecting top 'k' words that are more common in one sentiment category than the other.\n",
    "\n",
    "Finally, I printed out the lists of 10 content words that are representative of positive and negative reviews in my training data which is stored in **content_words_pos** and **content_words_neg** variables respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIDf9uUsd-7z",
    "outputId": "0ad53ec7-87d2-404a-d954-8cc9265403fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1a) List of 10 content words which are representative of positive reviews in training data: ['film', 'also', 'life', 'story', 'many', 'great', 'well', 'one', 'first', 'best']\n",
      "1b) List of 10 content words which are representative of negative reviews in training data: ['movie', 'bad', 'plot', 'worst', 'script', 'get', 'could', 'even', 'nothing', 'supposed']\n"
     ]
    }
   ],
   "source": [
    "#most common words function\n",
    "def most_freq_words(pos_freq,neg_freq,top_k):\n",
    "  diff=pos_freq-neg_freq\n",
    "  sort_diff=diff.most_common()\n",
    "  only_words = [words for (words,label) in sort_diff[:top_k]]\n",
    "  return only_words\n",
    "\n",
    "pos_freq_dist=FreqDist()\n",
    "neg_freq_dist=FreqDist()\n",
    "\n",
    "for reviewDist,label in training_norm:\n",
    "    if label=='pos':\n",
    "        pos_freq_dist+=reviewDist\n",
    "    else:\n",
    "        neg_freq_dist+=reviewDist\n",
    "\n",
    "content_words_pos = most_freq_words(pos_freq_dist,neg_freq_dist,10)\n",
    "content_words_neg = most_freq_words(neg_freq_dist,pos_freq_dist,10)\n",
    "\n",
    "print(f\"1a) List of 10 content words which are representative of positive reviews in training data: {content_words_pos}\")\n",
    "print(f\"1b) List of 10 content words which are representative of negative reviews in training data: {content_words_neg}\")\n",
    "\n",
    "#neg['movie', 'bad', 'plot', 'even', 'worst', 'stupid', 'script', 'could', 'least', 'get']\n",
    "#pos['film', 'life', 'also', 'best', 'great', 'story', 'well', 'many', 'world', 'performance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TApOQE6vND20"
   },
   "source": [
    "2)\n",
    "a) **Use** the lists generated in Q1 to build a **word list classifier** which will classify reviews as being positive or negative.\n",
    "\n",
    "b) **Explain** what you have done.\n",
    "\n",
    "[12.5\\%]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmHRoD_0_lNm"
   },
   "source": [
    "## **2a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "BThDMrcmODJy"
   },
   "outputs": [],
   "source": [
    "class SimpleClassifier(ClassifierI):\n",
    "    def __init__(self, pos, neg):\n",
    "        self._pos = pos\n",
    "        self._neg = neg\n",
    "\n",
    "    def classify(self, doc):\n",
    "        #doc is a FreqDist\n",
    "        score = 0\n",
    "\n",
    "        #this assigns an appropriate value to score\n",
    "        for word,value in doc.items():\n",
    "            if word in self._pos:\n",
    "                score+=value\n",
    "            if word in self._neg:\n",
    "                score-=value\n",
    "\n",
    "        return \"neg\" if score < 0 else  \"pos\"\n",
    "\n",
    "    #since classify_many method is already provided in ClassifierI we don't actually need to define it\n",
    "    def classify_many(self, docs):\n",
    "        return [self.classify(doc) for doc in docs]\n",
    "    def labels(self):\n",
    "        return (\"pos\", \"neg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C6vK5Vyz2XUF",
    "outputId": "4aa47b0d-35cd-4e6e-e774-c4841d996bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "classifier = SimpleClassifier(content_words_pos, content_words_neg)\n",
    "print(classifier.classify(FreqDist(\"This movie was great\".split())))\n",
    "print(classifier.classify(FreqDist(\"I hated this movie\".split())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "NGvyBrbIvjJt"
   },
   "outputs": [],
   "source": [
    "class SimpleClassifier_mf(SimpleClassifier):\n",
    "    def __init__(self,k):\n",
    "        self._k=k\n",
    "\n",
    "    def train(self,training_data):\n",
    "\n",
    "        pos_freq_dist=FreqDist()\n",
    "        neg_freq_dist=FreqDist()\n",
    "\n",
    "        for reviewDist,label in training_data:\n",
    "            if label=='pos':\n",
    "                pos_freq_dist+=reviewDist\n",
    "            else:\n",
    "                neg_freq_dist+=reviewDist\n",
    "\n",
    "        self._pos=most_freq_words(pos_freq_dist,neg_freq_dist,self._k)\n",
    "        self._neg=most_freq_words(neg_freq_dist,pos_freq_dist,self._k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "6LsszsBe1hew"
   },
   "outputs": [],
   "source": [
    "movie_classifier=SimpleClassifier_mf(10)\n",
    "movie_classifier.train(training_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "2sx5uC3a1wMW",
    "outputId": "e4aa5a17-1825-444a-e382-4026790c09c8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_classifier.classify(FreqDist(\"I hated this movie\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRFVw7dm13WQ",
    "outputId": "929a64e9-6649-4a37-87ce-fbf77349dceb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data,labels=zip(*testing_norm)\n",
    "movie_classifier.classify_many(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eAWoAO0E1XD"
   },
   "source": [
    "Here I am creating a Word List Classifier using the list generated in above.\n",
    "This is achieved by defining 2 classes SimpleClassifier and SimpleClassifier_mf.\n",
    "\n",
    "The ***SimpleClassifier class*** represents a text classifier that may classify a document as \"pos\" or \"neg\" based on the presence of terms or words in positive and negative lists.In that, ***classify method*** passes the words of a document. The logic is then written in such a way that each instance of a negative word decreases score and each instance of a positive word increases score.\n",
    "\n",
    "The ***classify_many method*** then applies the classification to several documents, and the labels method returns the labels that could be assigned (\"pos\" and \"neg\").\n",
    "\n",
    "Post this, I extend the ***SimpleClassifier class*** to include a train function for generating wordlists from training data. In this, the train method starts by processing training data, which is made up of tuples containing document frequency distributions (reviewDist) and labels (label). It collects word frequencies for positive and negative reviews separately and uses ***most_freq_words*** function defined in our earlier step to select the top words for each category based on a parameter ***k***.\n",
    "\n",
    "The 2 classes ***SimpleClassifier*** and ***SimpleClassifier_mf*** focuses on classifying and training the classifier respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZdDO_Y92XUH"
   },
   "source": [
    "3)\n",
    "a) **Calculate** the accuracy, precision, recall and F1 score of your classifier.\n",
    "\n",
    "b) Is it reasonable to evaluate the classifier in terms of its accuracy?  **Explain** your answer and give a counter-example (a scenario where it would / would not be reasonable to evaluate the classifier in terms of its accuracy).\n",
    "\n",
    "[20\\%]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NiSfgDQnwu1"
   },
   "source": [
    "## **3a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_i80ceP2XUJ",
    "outputId": "4d70cac3-8252-4bcc-c567-c5a198a25c6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision :  0.5738396624472574\n",
      "Recall : 0.9066666666666666\n",
      "F1 : 0.702842377260982\n",
      "accuracy : 0.6166666666666667\n"
     ]
    }
   ],
   "source": [
    "class ConfusionMatrix:\n",
    "    def __init__(self,predictions,goldstandard,classes=(\"pos\",\"neg\")):\n",
    "\n",
    "        (self.c1,self.c2)=classes\n",
    "        self.TP=0\n",
    "        self.FP=0\n",
    "        self.FN=0\n",
    "        self.TN=0\n",
    "        for p,g in zip(predictions,goldstandard):\n",
    "            if g==self.c1:\n",
    "                if p==self.c1:\n",
    "                    self.TP+=1\n",
    "                else:\n",
    "                    self.FN+=1\n",
    "\n",
    "            elif p==self.c1:\n",
    "                self.FP+=1\n",
    "            else:\n",
    "                self.TN+=1\n",
    "\n",
    "\n",
    "    def precision(self):\n",
    "        p=0\n",
    "        #this computes precision\n",
    "        p = self.TP / (self.TP + self.FP)\n",
    "\n",
    "        return p\n",
    "\n",
    "    def recall(self):\n",
    "        r=0\n",
    "        #this computes recall\n",
    "        r = self.TP / (self.TP + self.FN)\n",
    "        return r\n",
    "\n",
    "    def f1(self):\n",
    "        f1=0\n",
    "        p = self.precision()\n",
    "        r = self.recall()\n",
    "        #this computes f1\n",
    "        f1 = (2*p*r)/(p+r)\n",
    "        return f1\n",
    "\n",
    "    def accuracy(self):\n",
    "        acc = 0\n",
    "        acc = (self.TP + self.TN)/(self.TP + self.TN + self.FN + self.FP)\n",
    "        return acc\n",
    "\n",
    "docs,goldlabel=zip(*testing_norm)\n",
    "ConfusionM=ConfusionMatrix(classifier.classify_many(docs),goldlabel)\n",
    "ConfusionM.recall()\n",
    "\n",
    "print('Precision : ',ConfusionM.precision())\n",
    "print('Recall :', ConfusionM.recall())\n",
    "print('F1 :',ConfusionM.f1())\n",
    "print('accuracy :',ConfusionM.accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "VbYwwhcs2XUL"
   },
   "outputs": [],
   "source": [
    "classifier_WL = ConfusionM.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifo7IWCLn3BW"
   },
   "source": [
    "## **3b)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVZp0N5J2XUL"
   },
   "source": [
    "We need to evaluate how well a classifier works, below are the measures\n",
    "1. **Accuracy** is the proportion of things we got correct or classified correctly.\n",
    "2. **Error Rate** is a proportion of things that we got wrong.\n",
    "\n",
    "Yes, Accuracy is a good way to assess our model, when the data is balanced. On the other side, if the data is skewed, accuracy alone cannot be trusted to select a well-performing model. Measure of assessing actually depends on what we would be interested in.\n",
    "The two scenarios that I could discover are listed below.\n",
    "\n",
    "1. **Protecting Positives More than Negatives & vice versa:**\n",
    "Cases where its more crucial to protect the positives than the negatives & vice versa so we **dont** want to look at **overall accuracy**. suppose you have a film that is projected to earn an overwhelming amount of positive reviews.The movie studio would suffer a large loss if a positive review was not received (false negative).\n",
    "\n",
    "2. Another case where there is a **difficulty with accuracy** that occurs frequently is when we are attempting to predict what is **relevant vs irrelevant**. If our data is **skewed**, we may have **99%** irrelevant papers and **1%** useful documents for that assignment. Saying that everything is irrelevant is the simplest method to get **99%** correct on the data. This strategy, however, is neither instructive nor beneficial, particularly when the purpose is to identify the minority class (relevant papers).\n",
    "\n",
    "Depending on what you're looking for, accuracy and error rate may be too simple to quantify. Perhaps we should look more closely at what we are getting right and wrong, especially when the data is skewed, to find this we can use Confusion Matrix which tells us at what items the model is confusing in terms of the labels.\n",
    "\n",
    "Here from the Confusion Matrix we derive number of other measures like\n",
    "\n",
    "1. **Precision** - when prediction is made how reliable it is\n",
    "2. **Recall** - if we are trying to find these things how many do we find\n",
    "3. **F1 Score** - it's a trade off between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIS9UpmJNEAp"
   },
   "source": [
    "4)\n",
    "a)  **Construct** a Naive Bayes classifier (e.g., from NLTK).\n",
    "\n",
    "b)  **Compare** the performance of your word list classifier with the Naive Bayes classifier.  **Discuss** your results.\n",
    "\n",
    "[12.5\\%]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lgi4ZLEYIgSw"
   },
   "source": [
    "## **4a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gwjig-Y12XUN",
    "outputId": "55e520ea-954d-4502-f403-015a20dfda55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "classifier_nb = NaiveBayesClassifier.train(training_norm)\n",
    "classifier_nb.classify_many(docs)[:10] #to keep it presentable have included the [:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "me41gu14IsDM"
   },
   "source": [
    "## **4b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6MSvGPorjNS",
    "outputId": "96682bcf-7ec4-4b0c-898a-18f1be3f3b80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of my Wordlist Classifier = 0.6166666666666667\n",
      "Precision of my Wordlist classifier = 0.5738396624472574\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of my Wordlist Classifier = {ConfusionM.accuracy()}\") #Accuracy of Word List Classifier\n",
    "print(f\"Precision of my Wordlist classifier = {ConfusionM.precision()}\") #Precision of Word List Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "cxlDg-I9rO23"
   },
   "outputs": [],
   "source": [
    "NB_predictions=classifier_nb.classify_many(docs)\n",
    "NB_ConfusionM=ConfusionMatrix(NB_predictions,goldlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AUsYRMa2XUN",
    "outputId": "e48822d2-1976-44b5-fc0f-1d95e2c70752"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier = 0.6983333333333334\n",
      "Precision of Naive Bayes classifier = 0.6274089935760171\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of Naive Bayes Classifier = {NB_ConfusionM.accuracy()}\") #Accuracy of Naive Bayes Classifier\n",
    "print(f\"Precision of Naive Bayes classifier = {NB_ConfusionM.precision()}\") #Precision of Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bytPkuHf2XUO"
   },
   "source": [
    "The **Naive Bayes Classifier** **outperforms** the **Wordlist Classifier** in terms of precision. If you see it has a greater precision, which means that when it predicts a positive class, it is true about **62.74%** of the time, as opposed to the Wordlist Classifier's precision of about **57.38%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGDXaVDqOSfY"
   },
   "source": [
    "5)\n",
    "a) Design and **carry out an experiment** into the impact of the **length of the wordlists** on the wordlist classifier.  Make sure you **describe** design decisions in your experiment, include a **graph** of your results and **discuss** your conclusions.\n",
    "\n",
    "b) Would you **recommend** a wordlist classifier or a Naive Bayes classifier for future work in this area?  **Justify** your answer.\n",
    "\n",
    "[25\\%]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlxoUthX2XUP"
   },
   "source": [
    "## **5a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "20nkvKrrN_B1"
   },
   "outputs": [],
   "source": [
    "def classifier_evaluate(cls, test_data):\n",
    "    acc = 0\n",
    "    docs,goldstandard=zip(*test_data) #note this neat pythonic way of turning a list of pairs into a pair of lists\n",
    "    #pass all of the docs to the classifier and get back a list of predictions\n",
    "    predictions=cls.classify_many(docs)\n",
    "    #zip the predictions with the goldstandard labels and compare\n",
    "    for prediction,goldlabel in zip(predictions,goldstandard):\n",
    "        if prediction==goldlabel:\n",
    "            acc+=1\n",
    "\n",
    "    return acc / (len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "T1L7mZ-k2XUQ"
   },
   "outputs": [],
   "source": [
    "word_list_size = 50\n",
    "samplesizes=[1,10,50,100,200,400,600]\n",
    "classifiers={\"classifier1\": SimpleClassifier_mf(word_list_size)}\n",
    "results={}\n",
    "acc_res={}\n",
    "pre_res={}\n",
    "wordlen={}\n",
    "recal_res={}\n",
    "f1_res={}\n",
    "\n",
    "number_of_runs = 3\n",
    "for i in samplesizes:\n",
    "    for j in range(number_of_runs):\n",
    "\n",
    "        content_words_pos=most_freq_words(pos_freq_dist,neg_freq_dist,i) #create different size of positive wordlist\n",
    "        content_words_neg=most_freq_words(neg_freq_dist,pos_freq_dist,i) #create different size of negative wordlist\n",
    "\n",
    "        classifier = SimpleClassifier(content_words_pos,content_words_neg)\n",
    "        #confusion matrix\n",
    "        docs,goldlabels=zip(*testing_norm)\n",
    "        CM=ConfusionMatrix(classifier.classify_many(docs),goldlabels)\n",
    "        wordlen[i]=i\n",
    "        pre_res[i] = pre_res.get(i,0)+(CM.precision()/number_of_runs)\n",
    "        recal_res[i] = recal_res.get(i,0)+(CM.recall()/number_of_runs)\n",
    "        f1_res[i] = f1_res.get(i,0)+(CM.f1()/number_of_runs)\n",
    "        acc_res[i] = acc_res.get(i,0)+(CM.accuracy()/number_of_runs)\n",
    "    results[\"word_list\"] = wordlen\n",
    "    results[\"accuracy\"] = acc_res\n",
    "    results[\"precision\"] = pre_res\n",
    "    results[\"recall\"] = recal_res\n",
    "    results[\"f1 score\"] = f1_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "3CAxAPWDrrDR",
    "outputId": "823d815b-3e6e-462f-ff33-52a89e16103f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word_list': {1: 1, 10: 10, 50: 50, 100: 100, 200: 200, 400: 400, 600: 600}, 'accuracy': {1: 0.55, 10: 0.6166666666666667, 50: 0.6266666666666667, 100: 0.6566666666666666, 200: 0.5933333333333334, 400: 0.5866666666666667, 600: 0.5866666666666667}, 'precision': {1: 0.5360576923076923, 10: 0.5738396624472574, 50: 0.576, 100: 0.5971074380165289, 200: 0.551660516605166, 400: 0.5477941176470589, 600: 0.5477941176470589}, 'recall': {1: 0.7433333333333333, 10: 0.9066666666666667, 50: 0.96, 100: 0.9633333333333334, 200: 0.9966666666666668, 400: 0.9933333333333332, 600: 0.9933333333333332}, 'f1 score': {1: 0.6229050279329608, 10: 0.702842377260982, 50: 0.7199999999999999, 100: 0.7372448979591837, 200: 0.7102137767220902, 400: 0.7061611374407584, 600: 0.7061611374407584}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-68487bca-f012-4394-b497-562e23c37ea7\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_list</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.536058</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>0.622905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.573840</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.702842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>0.597107</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.737245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>200</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.551661</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.710214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>400</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.547794</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.706161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>600</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.547794</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.706161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68487bca-f012-4394-b497-562e23c37ea7')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-68487bca-f012-4394-b497-562e23c37ea7 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-68487bca-f012-4394-b497-562e23c37ea7');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-8e01c520-15d2-42d0-b8ec-08525d5a9dc6\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8e01c520-15d2-42d0-b8ec-08525d5a9dc6')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-8e01c520-15d2-42d0-b8ec-08525d5a9dc6 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "     word_list  accuracy  precision    recall  f1 score\n",
       "1            1  0.550000   0.536058  0.743333  0.622905\n",
       "10          10  0.616667   0.573840  0.906667  0.702842\n",
       "50          50  0.626667   0.576000  0.960000  0.720000\n",
       "100        100  0.656667   0.597107  0.963333  0.737245\n",
       "200        200  0.593333   0.551661  0.996667  0.710214\n",
       "400        400  0.586667   0.547794  0.993333  0.706161\n",
       "600        600  0.586667   0.547794  0.993333  0.706161"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(results)\n",
    "df=pd.DataFrame(results)\n",
    "# df=df.transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "xFeOWIRm2XUQ",
    "outputId": "ad7299da-b1ea-4f46-c9d7-6add6f9deaac"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting a bar graph for each word list size\n",
    "df.set_index('word_list').plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Evaluation Metrics for Different Word List Sizes')\n",
    "plt.xlabel('Word List Size')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(title='Metrics', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5y9GQppIrqLo"
   },
   "source": [
    "Each line in the figure, depicts the trend of a given statistic (precision, recall, f1 score, accuracy) as the word list size grows. In this case, the precision, recall, f1 score, or accuracy rises as the word list size grows.\n",
    "\n",
    "After a certain point, it begins to exhibit decreasing returns or begins to stabilize(sample size about 200). After this moment, performance appears to be slightly declining, indicating that extending the word list beyond that point may not significantly enhance performance.\n",
    "\n",
    "For all sample sizes, the wordlist classifier using the 200 most frequent terms appears to outperform the wordlist classifier.\n",
    "\n",
    "Considering the factors discussed, as the classification task involved a dynamic and evolving language context, and a sufficiently large and diverse dataset, I would recommend using a Naive Bayes classifier.\n",
    "\n",
    "The dynamic and evolving nature of the language context connected with the activity motivates this option. It also excels at adapting to new words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34rdlS_iPov6",
    "outputId": "756703d6-9384-49f9-9150-23db2896d3d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Submission length is 1173\n"
     ]
    }
   ],
   "source": [
    "##This code will word count all of the markdown cells in the notebook saved at filepath\n",
    "\n",
    "import io\n",
    "from nbformat import current\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "filepath=\"/content/drive/MyDrive/Colab Notebooks/ANLPassignment2023.ipynb\"\n",
    "question_count=432\n",
    "\n",
    "with io.open(filepath, 'r', encoding='utf-8') as f:\n",
    "    nb = current.read(f, 'json')\n",
    "\n",
    "word_count = 0\n",
    "for cell in nb.worksheets[0].cells:\n",
    "    if cell.cell_type == \"markdown\":\n",
    "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
    "print(\"Submission length is {}\".format(word_count-question_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "L1f5Rw2u4U9v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
